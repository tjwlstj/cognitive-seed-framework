# M05: Concept Crystallizer - êµ¬í˜„ ê°€ì´ë“œ

## ë¬¸ì„œ ë¶„ë¥˜

ì´ ë¬¸ì„œëŠ” **êµ¬í˜„ ê°€ì´ë“œ**ì…ë‹ˆë‹¤.
- ğŸ“š **ì •ë³´ ìë£Œ**: `M05_RESEARCH_MATERIALS.md`
- ğŸ“– **êµ¬í˜„ ê°€ì´ë“œ**: ë³¸ ë¬¸ì„œ (M05_IMPLEMENTATION_GUIDE.md)
- ğŸ’» **í”„ë¡œì íŠ¸ ì½”ë“œ**: `seeds/molecular/m05_concept_crystallizer.py`
- ğŸ§ª **í™œìš© ì˜ˆì œ**: `examples/m05_usage_examples.py`

---

## ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [ì„¤ê³„ ëª…ì„¸](#2-ì„¤ê³„-ëª…ì„¸)
3. [ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ](#3-ë‹¨ê³„ë³„-êµ¬í˜„-ê°€ì´ë“œ)
4. [í…ŒìŠ¤íŠ¸ ì „ëµ](#4-í…ŒìŠ¤íŠ¸-ì „ëµ)
5. [ì„±ëŠ¥ ìµœì í™”](#5-ì„±ëŠ¥-ìµœì í™”)
6. [ì°¸ê³  ìë£Œ](#6-ì°¸ê³ -ìë£Œ)

---

## 1. ê°œìš”

### 1.1 ê¸°ë³¸ ì •ë³´

- **ì‹œë“œ ID**: SEED-M05
- **ì´ë¦„**: Concept Crystallizer
- **Level**: 1 (Molecular)
- **Category**: Abstraction
- **Target Params**: ~700K
- **Bit Depth**: FP8

### 1.2 ëª©ì 

ì†Œìˆ˜ì˜ ì˜ˆì œë¡œë¶€í„° **ê°œë…ì˜ í”„ë¡œí† íƒ€ì… í‘œí˜„ì„ í•™ìŠµ**í•˜ê³ , ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•´ë‹¹ ê°œë…ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. Few-shot learningì„ í†µí•´ ë°ì´í„°ê°€ ì œí•œëœ í™˜ê²½ì—ì„œë„ ê°•ë ¥í•œ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.

### 1.3 êµ¬ì„± ì‹œë“œ

- **A05**: Grouping Nucleus (êµ°ì§‘í™” ë° ê·¸ë£¹ í‘œí˜„)
- **M03**: Pattern Completer (íŒ¨í„´ ì™„ì„± ë° ë³´ê°„)
- **M01**: Hierarchy Builder (ê³„ì¸µì  êµ¬ì¡° í•™ìŠµ)

### 1.4 í•µì‹¬ ê¸°ëŠ¥

1. **Prototype Learning**
   - Few-shot ì˜ˆì œë¡œë¶€í„° í´ë˜ìŠ¤ í”„ë¡œí† íƒ€ì… í•™ìŠµ
   - Embedding spaceì—ì„œ ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜

2. **Concept Abstraction**
   - ê³„ì¸µì  ê°œë… í‘œí˜„ (M01)
   - íŒ¨í„´ ê¸°ë°˜ ì¼ë°˜í™” (M03)

3. **Meta-Learning**
   - Episode-based í•™ìŠµ
   - Support setê³¼ Query set êµ¬ë¶„

4. **Distance-based Classification**
   - Euclidean distance ë˜ëŠ” Cosine similarity
   - Softmax over distances

---

## 2. ì„¤ê³„ ëª…ì„¸

### 2.1 ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```
Support Set [N, K, D]    Query Set [Q, D]
    â”‚                         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                         â”‚
    â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedding Net  â”‚   â”‚  Embedding Net  â”‚
â”‚  (ê³µìœ )         â”‚   â”‚  (ê³µìœ )         â”‚
â”‚  - A05 (ê·¸ë£¹)   â”‚   â”‚  - A05 (ê·¸ë£¹)   â”‚
â”‚  - M03 (íŒ¨í„´)   â”‚   â”‚  - M03 (íŒ¨í„´)   â”‚
â”‚  - M01 (ê³„ì¸µ)   â”‚   â”‚  - M01 (ê³„ì¸µ)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                         â”‚
    â–¼                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚ Prototype       â”‚           â”‚
â”‚ Computation     â”‚           â”‚
â”‚ (mean pooling)  â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
    â”‚                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Distance      â”‚
       â”‚ Computation   â”‚
       â”‚ (Euclidean)   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Classificationâ”‚
       â”‚ (Softmax)     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
       Output [Q, N]
```

### 2.2 ì…ì¶œë ¥ ëª…ì„¸

#### ì…ë ¥ (Episode ê¸°ë°˜)
- `support_set`: `[N, K, D]` - Nê°œ í´ë˜ìŠ¤, ê° Kê°œ ì˜ˆì œ
- `query_set`: `[Q, D]` - Qê°œ ì¿¼ë¦¬ ìƒ˜í”Œ
- `N`: N-way (í´ë˜ìŠ¤ ìˆ˜)
- `K`: K-shot (í´ë˜ìŠ¤ë‹¹ ì˜ˆì œ ìˆ˜)

#### ì¶œë ¥
- `logits`: `[Q, N]` - ê° ì¿¼ë¦¬ì˜ í´ë˜ìŠ¤ë³„ ë¡œì§“
- `predictions`: `[Q]` - ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤

#### ë©”íƒ€ë°ì´í„°
```python
{
    'prototypes': Tensor,         # [N, D] - ê° í´ë˜ìŠ¤ì˜ í”„ë¡œí† íƒ€ì…
    'embeddings': Tensor,         # [N*K+Q, D] - ëª¨ë“  ì„ë² ë”©
    'distances': Tensor,          # [Q, N] - ì¿¼ë¦¬-í”„ë¡œí† íƒ€ì… ê±°ë¦¬
    'support_embeddings': Tensor, # [N, K, D]
    'query_embeddings': Tensor    # [Q, D]
}
```

### 2.3 íŒŒë¼ë¯¸í„° ì˜ˆì‚°

| ì»´í¬ë„ŒíŠ¸ | íŒŒë¼ë¯¸í„° ìˆ˜ | ë¹„ìœ¨ |
|---------|-----------|------|
| A05 (Grouping Nucleus) | ~100K | 14% |
| M03 (Pattern Completer) | ~550K | 79% |
| M01 (Hierarchy Builder) | ~426K | 61% |
| **ê¸°ì¡´ ì‹œë“œ í•©ê³„** | **~1,076K** | **154%** |
| Shared Embedding Layers | -376K | -54% |
| Distance Metric Layer | ~0.5K | 0.1% |
| **ì‹¤ì œ ì´í•©** | **~700K** | **100%** |

**ì°¸ê³ **: ì‹œë“œë“¤ì´ ê³µìœ  ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì œê±°

---

## 3. ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ

### Step 1: í”„ë¡œì íŠ¸ êµ¬ì¡° ì¤€ë¹„

#### 1.1 íŒŒì¼ ìƒì„±

```bash
# ë©”ì¸ êµ¬í˜„ íŒŒì¼
touch seeds/molecular/m05_concept_crystallizer.py

# í™œìš© ì˜ˆì œ íŒŒì¼
mkdir -p examples
touch examples/m05_usage_examples.py

# í…ŒìŠ¤íŠ¸ íŒŒì¼
mkdir -p tests/molecular
touch tests/molecular/test_m05_concept_crystallizer.py
```

#### 1.2 ê¸°ë³¸ í´ë˜ìŠ¤ êµ¬ì¡°

```python
# seeds/molecular/m05_concept_crystallizer.py
import torch
import torch.nn as nn
from typing import Dict, Tuple, Optional
from ..atomic.a05_grouping_nucleus import GroupingNucleus
from .m03_pattern_completer import PatternCompleter
from .m01_hierarchy_builder import HierarchyBuilder

class ConceptCrystallizer(nn.Module):
    """
    M05: Concept Crystallizer
    
    Few-shot learningì„ í†µí•´ ê°œë…ì˜ í”„ë¡œí† íƒ€ì…ì„ í•™ìŠµí•˜ê³ 
    ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Args:
        input_dim: ì…ë ¥ ì°¨ì›
        hidden_dim: ì€ë‹‰ ì°¨ì›
        n_way: N-way classification (í´ë˜ìŠ¤ ìˆ˜)
        k_shot: K-shot learning (í´ë˜ìŠ¤ë‹¹ ì˜ˆì œ ìˆ˜)
        distance_metric: 'euclidean' or 'cosine'
    """
    
    def __init__(
        self,
        input_dim: int = 64,
        hidden_dim: int = 128,
        n_way: int = 5,
        k_shot: int = 5,
        distance_metric: str = 'euclidean'
    ):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.n_way = n_way
        self.k_shot = k_shot
        self.distance_metric = distance_metric
        
        # êµ¬ì„± ì‹œë“œë“¤
        self.grouping = GroupingNucleus(input_dim, hidden_dim)
        self.pattern_completer = PatternCompleter(hidden_dim)
        self.hierarchy = HierarchyBuilder(hidden_dim)
        
        # ì„ë² ë”© ë„¤íŠ¸ì›Œí¬ (ê³µìœ )
        self.embedding_net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
    def compute_prototypes(
        self, 
        support_embeddings: torch.Tensor
    ) -> torch.Tensor:
        """
        Support setìœ¼ë¡œë¶€í„° í”„ë¡œí† íƒ€ì… ê³„ì‚°
        
        Args:
            support_embeddings: [N, K, D]
        
        Returns:
            prototypes: [N, D]
        """
        # ê° í´ë˜ìŠ¤ì˜ í‰ê·  ì„ë² ë”©ì„ í”„ë¡œí† íƒ€ì…ìœ¼ë¡œ ì‚¬ìš©
        prototypes = support_embeddings.mean(dim=1)
        return prototypes
    
    def compute_distances(
        self,
        query_embeddings: torch.Tensor,
        prototypes: torch.Tensor
    ) -> torch.Tensor:
        """
        ì¿¼ë¦¬ì™€ í”„ë¡œí† íƒ€ì… ê°„ ê±°ë¦¬ ê³„ì‚°
        
        Args:
            query_embeddings: [Q, D]
            prototypes: [N, D]
        
        Returns:
            distances: [Q, N]
        """
        if self.distance_metric == 'euclidean':
            # Euclidean distance
            # [Q, 1, D] - [1, N, D] -> [Q, N, D]
            diff = query_embeddings.unsqueeze(1) - prototypes.unsqueeze(0)
            distances = torch.norm(diff, dim=2)
        elif self.distance_metric == 'cosine':
            # Cosine similarity (ìŒìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ê±°ë¦¬ì²˜ëŸ¼ ì‚¬ìš©)
            query_norm = query_embeddings / query_embeddings.norm(dim=1, keepdim=True)
            proto_norm = prototypes / prototypes.norm(dim=1, keepdim=True)
            distances = -torch.mm(query_norm, proto_norm.t())
        else:
            raise ValueError(f"Unknown distance metric: {self.distance_metric}")
        
        return distances
    
    def forward(
        self,
        support_set: torch.Tensor,
        query_set: torch.Tensor,
        return_metadata: bool = False
    ) -> Tuple[torch.Tensor, Optional[Dict]]:
        """
        Forward pass
        
        Args:
            support_set: [N, K, D] - Support set
            query_set: [Q, D] - Query set
            return_metadata: ë©”íƒ€ë°ì´í„° ë°˜í™˜ ì—¬ë¶€
        
        Returns:
            logits: [Q, N] - í´ë˜ìŠ¤ë³„ ë¡œì§“
            metadata: ë©”íƒ€ë°ì´í„° (ì„ íƒì )
        """
        N, K, D = support_set.shape
        Q = query_set.shape[0]
        
        # 1. Support set ì„ë² ë”©
        # [N, K, D] -> [N*K, D]
        support_flat = support_set.view(N * K, D)
        support_emb = self.embedding_net(support_flat)
        
        # êµ¬ì„± ì‹œë“œ ì ìš©
        support_emb = self.grouping(support_emb.unsqueeze(0)).squeeze(0)
        support_emb = self.pattern_completer(support_emb.unsqueeze(0)).squeeze(0)
        support_emb = self.hierarchy(support_emb.unsqueeze(0)).squeeze(0)
        
        # [N*K, D] -> [N, K, D]
        support_embeddings = support_emb.view(N, K, -1)
        
        # 2. Query set ì„ë² ë”©
        query_emb = self.embedding_net(query_set)
        query_emb = self.grouping(query_emb.unsqueeze(0)).squeeze(0)
        query_emb = self.pattern_completer(query_emb.unsqueeze(0)).squeeze(0)
        query_emb = self.hierarchy(query_emb.unsqueeze(0)).squeeze(0)
        query_embeddings = query_emb
        
        # 3. í”„ë¡œí† íƒ€ì… ê³„ì‚°
        prototypes = self.compute_prototypes(support_embeddings)
        
        # 4. ê±°ë¦¬ ê³„ì‚°
        distances = self.compute_distances(query_embeddings, prototypes)
        
        # 5. ë¡œì§“ ê³„ì‚° (ê±°ë¦¬ì˜ ìŒìˆ˜ë¥¼ ë¡œì§“ìœ¼ë¡œ ì‚¬ìš©)
        logits = -distances
        
        # 6. ì˜ˆì¸¡
        predictions = torch.argmax(logits, dim=1)
        
        if return_metadata:
            metadata = {
                'prototypes': prototypes,
                'embeddings': torch.cat([support_emb, query_emb], dim=0),
                'distances': distances,
                'support_embeddings': support_embeddings,
                'query_embeddings': query_embeddings,
                'predictions': predictions
            }
            return logits, metadata
        
        return logits, None
```

### Step 2: í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±

```python
# tests/molecular/test_m05_concept_crystallizer.py
import torch
import pytest
from seeds.molecular.m05_concept_crystallizer import ConceptCrystallizer

def test_concept_crystallizer_basic():
    """ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸"""
    model = ConceptCrystallizer(
        input_dim=64,
        hidden_dim=128,
        n_way=5,
        k_shot=5
    )
    
    # 5-way 5-shot
    support_set = torch.randn(5, 5, 64)
    query_set = torch.randn(10, 64)
    
    logits, metadata = model(support_set, query_set, return_metadata=True)
    
    assert logits.shape == (10, 5)
    assert metadata['prototypes'].shape == (5, 128)
    assert metadata['predictions'].shape == (10,)

def test_few_shot_learning():
    """Few-shot í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜"""
    model = ConceptCrystallizer(n_way=3, k_shot=3)
    
    # ê°„ë‹¨í•œ í•©ì„± ë°ì´í„°
    # í´ë˜ìŠ¤ 0: [1, 0, 0, ...]
    # í´ë˜ìŠ¤ 1: [0, 1, 0, ...]
    # í´ë˜ìŠ¤ 2: [0, 0, 1, ...]
    support_set = torch.zeros(3, 3, 64)
    for i in range(3):
        support_set[i, :, i] = 1.0
    
    query_set = torch.zeros(3, 64)
    query_set[0, 0] = 1.0  # í´ë˜ìŠ¤ 0
    query_set[1, 1] = 1.0  # í´ë˜ìŠ¤ 1
    query_set[2, 2] = 1.0  # í´ë˜ìŠ¤ 2
    
    logits, metadata = model(support_set, query_set, return_metadata=True)
    predictions = metadata['predictions']
    
    # ì •í™•íˆ ë¶„ë¥˜ë˜ì–´ì•¼ í•¨
    assert predictions[0] == 0
    assert predictions[1] == 1
    assert predictions[2] == 2

if __name__ == '__main__':
    pytest.main([__file__, '-v'])
```

### Step 3: í™œìš© ì˜ˆì œ ì‘ì„±

```python
# examples/m05_usage_examples.py
import torch
from seeds.molecular.m05_concept_crystallizer import ConceptCrystallizer

def example_omniglot_style():
    """Omniglot ìŠ¤íƒ€ì¼ ë¬¸ì ì¸ì‹"""
    print("=== Omniglot-style Character Recognition ===")
    
    model = ConceptCrystallizer(
        input_dim=784,  # 28x28 ì´ë¯¸ì§€
        hidden_dim=256,
        n_way=5,
        k_shot=1  # 1-shot learning
    )
    
    # 5ê°œ í´ë˜ìŠ¤, ê° 1ê°œ ì˜ˆì œ
    support_set = torch.randn(5, 1, 784)
    query_set = torch.randn(20, 784)
    
    logits, metadata = model(support_set, query_set, return_metadata=True)
    
    print(f"Support set: {support_set.shape}")
    print(f"Query set: {query_set.shape}")
    print(f"Logits: {logits.shape}")
    print(f"Predictions: {metadata['predictions']}")
    print(f"Prototypes: {metadata['prototypes'].shape}")

def example_concept_learning():
    """ê°œë… í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜"""
    print("\n=== Concept Learning Simulation ===")
    
    model = ConceptCrystallizer(n_way=3, k_shot=5)
    
    # 3ê°œ ê°œë…, ê° 5ê°œ ì˜ˆì œ
    support_set = torch.randn(3, 5, 64)
    query_set = torch.randn(15, 64)
    
    logits, metadata = model(support_set, query_set, return_metadata=True)
    
    # ê° ì¿¼ë¦¬ì˜ ê°€ì¥ ê°€ê¹Œìš´ í”„ë¡œí† íƒ€ì… í™•ì¸
    distances = metadata['distances']
    min_distances, predictions = torch.min(distances, dim=1)
    
    print(f"Query predictions: {predictions}")
    print(f"Min distances: {min_distances}")

if __name__ == '__main__':
    example_omniglot_style()
    example_concept_learning()
```

---

## 4. í…ŒìŠ¤íŠ¸ ì „ëµ

### 4.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

1. **í”„ë¡œí† íƒ€ì… ê³„ì‚° í…ŒìŠ¤íŠ¸**
   - Support setìœ¼ë¡œë¶€í„° ì •í™•í•œ í‰ê·  ê³„ì‚° í™•ì¸

2. **ê±°ë¦¬ ê³„ì‚° í…ŒìŠ¤íŠ¸**
   - Euclidean ë° Cosine ê±°ë¦¬ ì •í™•ì„± ê²€ì¦

3. **Few-shot ë¶„ë¥˜ í…ŒìŠ¤íŠ¸**
   - ê°„ë‹¨í•œ í•©ì„± ë°ì´í„°ë¡œ ì •í™•í•œ ë¶„ë¥˜ í™•ì¸

### 4.2 í†µí•© í…ŒìŠ¤íŠ¸

1. **N-way K-shot ë³€í˜• í…ŒìŠ¤íŠ¸**
   - ë‹¤ì–‘í•œ N, K ì¡°í•©ì—ì„œ ë™ì‘ í™•ì¸

2. **ë©”íƒ€ëŸ¬ë‹ ì‹œë®¬ë ˆì´ì…˜**
   - Episode ê¸°ë°˜ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ê²€ì¦

### 4.3 ë²¤ì¹˜ë§ˆí¬

- **Omniglot**: 1-shot, 5-way ë¶„ë¥˜
- **Mini-ImageNet**: 5-shot, 5-way ë¶„ë¥˜
- **ëª©í‘œ ì •í™•ë„**: â‰¥ 85%

---

## 5. ì„±ëŠ¥ ìµœì í™”

### 5.1 íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±

- ê³µìœ  ì„ë² ë”© ë ˆì´ì–´ ì‚¬ìš©
- ê²½ëŸ‰ ê±°ë¦¬ ê³„ì‚° ëª¨ë“ˆ

### 5.2 FP8 ì–‘ìí™”

```python
# FP8 ì–‘ìí™” ì ìš©
model = ConceptCrystallizer(...)
model = model.to(torch.float8_e4m3fn)
```

### 5.3 ë°°ì¹˜ ì²˜ë¦¬

- Episode ë‹¨ìœ„ ë°°ì¹˜ ì²˜ë¦¬
- ë³‘ë ¬ í”„ë¡œí† íƒ€ì… ê³„ì‚°

---

## 6. ì°¸ê³  ìë£Œ

1. **Prototypical Networks** (Snell et al., 2017)
   - https://arxiv.org/abs/1703.05175

2. **Meta-Learning Survey** (Hospedales et al., 2021)
   - https://ieeexplore.ieee.org/document/9428530

3. **Few-Shot Learning Benchmark**
   - Omniglot, Mini-ImageNet ë°ì´í„°ì…‹

---

**ì‘ì„±ì¼**: 2025-11-02  
**ì‘ì„±ì**: Manus AI  
**ë²„ì „**: 1.0
