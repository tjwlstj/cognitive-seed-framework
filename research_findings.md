# 시드 제작 관련 최신 문헌 및 자료 조사 결과

조사 일시: 2025-10-20
조사자: 누스양

## 1. 모듈식 신경망 및 조합 학습 (Modular & Compositional Learning)

### 주요 논문

1. **Emergence and maintenance of modularity in neural networks** (2025)
   - URL: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012973
   - 저자: R Bergoin et al.
   - 인용: 2회
   - 핵심: 억제 뉴런이 스파이킹 신경망의 모듈성 출현과 장기 유지에 필수적임을 발견

2. **Predicting modular functions and neural coding of behavior** (2024)
   - URL: https://www.nature.com/articles/s41593-024-01784-3
   - 저자: A Vishwanathan et al.
   - 인용: 38회
   - 핵심: 재구성된 배선 다이어그램 기반 신경망 모델로 세포 수준 행동 코딩 예측

3. **The Potential of Cognitive-Inspired Neural Network Modeling** (2025)
   - URL: https://advanced.onlinelibrary.wiley.com/doi/10.1002/advs.202507730
   - 날짜: 2025-08-19
   - 핵심: 인지 기능과 정렬된 5개 모듈로 구성된 완전한 인지 아키텍처 (VCogM)

4. **Compositional Learning for Modular Multi-Agent Self-Organizing** (2024)
   - URL: https://arxiv.org/html/2506.02616v1
   - 핵심: CDRL(Compositional Deep RL)과 CPDM(Compositional Predictive Decision-Making) 제안

5. **Task-Driven Modular Networks for Zero-Shot Compositional Learning** (2019)
   - URL: https://openaccess.thecvf.com/content_ICCV_2019/papers/Purushwalkam_Task-Driven_Modular_Networks_for_Zero-Shot_Compositional_Learning_ICCV_2019_paper.pdf
   - 저자: S Purushwalkam et al.
   - 인용: 239회
   - 핵심: 의미 공간의 작은 신경 모듈을 태스크로 구성하여 모듈 재배선으로 새로운 개념 인식

6. **Modularity is the Bedrock of Natural and Artificial Intelligence**
   - URL: https://openreview.net/forum?id=kqrnhp3nNS
   - 핵심: 대부분의 복잡한 시스템이 계층적 모듈 구조인 이유와 조합적 일반화 가능 아키텍처

---

## 2. 다중 기하학 투영 및 리만 기하학 (Multi-Geometry & Riemannian Geometry)

### 주요 논문

1. **Hyperbolic Deep Neural Networks: A Survey** (2021)
   - URL: https://arxiv.org/pdf/2101.04562
   - 저자: W Peng et al.
   - 인용: 303회
   - 핵심: 쌍곡 이미지 임베딩, 이미지 분류 및 사람 재식별 등 컴퓨터 비전 태스크 적용

2. **Fully Hyperbolic Neural Networks** (2024)
   - URL: https://www.biorxiv.org/content/10.1101/2024.10.01.616153v1.full-text
   - 날짜: 2024-10-03
   - 핵심: MEG 뇌 네트워크의 노화 궤적 연구를 위한 쌍곡 임베딩 최초 평가

3. **Spherical and hyperbolic embeddings of data** (2014)
   - URL: https://eprints.whiterose.ac.uk/id/eprint/78407/1/SphericalFinal.pdf
   - 저자: RC Wilson et al.
   - 인용: 170회
   - 핵심: 대칭 비유사도 데이터의 구면 및 쌍곡 임베딩 문제 효율적 해결

4. **Nested Hyperbolic Spaces for Dimensionality Reduction** (2022)
   - URL: https://pmc.ncbi.nlm.nih.gov/articles/PMC9997089/
   - 저자: X Fan et al.
   - 인용: 21회
   - 핵심: 투영(임베딩) 후 내재적 집계를 사용하는 완전 쌍곡 신경망

5. **RiemannGFM: Learning a Graph Foundation Model from Riemannian Geometry** (2025)
   - URL: https://arxiv.org/abs/2502.03251
   - 저자: L Sun et al.
   - 인용: 11회
   - 핵심: 다양한 기하학을 통합하는 product bundle 구성 범용 사전학습 모델

6. **Hyperbolic image embeddings** (2020)
   - URL: http://openaccess.thecvf.com/content_CVPR_2020/html/Khrulkov_Hyperbolic_Image_Embeddings_CVPR_2020_paper.html
   - 저자: V Khrulkov et al.
   - 인용: 435회
   - 핵심: 쌍곡 기하학이 유클리드/구면 임베딩 대비 성능 향상

7. **The Riemannian geometry of deep generative models** (2018)
   - URL: http://openaccess.thecvf.com/content_cvpr_2018_workshops/w10/html/Shao_The_Riemannian_Geometry_CVPR_2018_paper.html
   - 저자: H Shao et al.
   - 인용: 216회
   - 핵심: 심층 생성 모델이 학습한 매니폴드의 리만 기하학 연구

8. **Symmetry-driven embedding of networks in hyperbolic space** (2025)
   - URL: https://www.nature.com/articles/s42005-025-02122-0
   - 저자: S Lizotte et al.
   - 인용: 2회
   - 핵심: 베이지안 쌍곡 랜덤 그래프 모델의 사후 분포 샘플링 MCMC 알고리즘 (BIGUE)

---

## 3. 스케일 등변성 및 조건부 정규화 (Scale-Equivariance & Conditional Normalization)

### 주요 논문

1. **Scale-Equivariant Deep Learning for 3D Data** (2023)
   - URL: https://arxiv.org/abs/2304.05864
   - 저자: T Wimmer et al.
   - 인용: 8회
   - 핵심: 2차원 도메인의 스케일 등변 신경망에 대한 이론적 기초 및 과학적 연구 개요

2. **Truly Scale-Equivariant Deep Nets with Fourier Layers** (2023)
   - URL: https://arxiv.org/abs/2311.02922
   - 저자: MA Rahman et al.
   - 인용: 15회
   - 핵심: 가중치 공유 및 커널 리사이징을 통한 스케일 등변 CNN 개발 진전

3. **Scale-Equivariant U-Net** (2022)
   - URL: https://bmvc2022.mpi-inf.mpg.de/0763.pdf
   - 저자: M Sangalli et al.
   - 인용: 22회
   - 핵심: 완전 합성곱 신경망으로 특정 평행이동 부분군에 등변

4. **Scale Equivariant Graph Metanetworks** (2024)
   - URL: https://openreview.net/forum?id=8Fxqn1tZM1
   - 저자: I Kalogeropoulos et al.
   - 인용: 17회
   - 핵심: 입력 신경망의 비선형성으로 유도된 스케일링 대칭에 등변인 GNN 기반 메타네트워크

5. **Scale-Equivariant Neural Networks with Decomposed Convolutions** (2019)
   - URL: https://ww3.math.ucla.edu/camreport/cam19-47.pdf
   - 저자: W Zhu et al.
   - 인용: 28회
   - 핵심: 공간과 스케일링 그룹에 걸친 결합 합성곱을 가진 스케일 등변 CNN 아키텍처

6. **FiLM: Visual reasoning with a general conditioning layer** (2018)
   - URL: https://ojs.aaai.org/index.php/AAAI/article/view/11671
   - 핵심: 조건부 정규화(Conditional Normalization)와 FiLM의 관계 평가 ablation 연구

7. **Scale Invariance of Graph Neural Networks** (2024)
   - URL: https://arxiv.org/abs/2411.19392
   - 저자: Q Jiang et al.
   - 핵심: 그래프에서 스케일 불변성 확립 및 증명, 그래프 학습으로 확장

8. **Enabling scale and rotation invariance in CNNs** (2025)
   - URL: https://www.sciencedirect.com/science/article/abs/pii/S0893608025002746
   - 저자: J Zhang et al.
   - 핵심: 망막 모듈 제안 및 CNN 통합으로 변환 불변 CNN(TICNN) 생성

---

## 4. 신경망 양자화 (Neural Network Quantization)

### 주요 논문

1. **Efficient Post-training Quantization with FP8 Formats** (2024)
   - URL: https://proceedings.mlsys.org/paper_files/paper/2024/file/dea9b4b6f55ae611c54065d6fc750755-Paper-Conference.pdf
   - 저자: H Shen et al.
   - 인용: 32회
   - 핵심: FP8 포맷이 DNN 양자화를 위한 INT8보다 효율적이고 생산적인 대안임을 주장

2. **FP8 Quantization: The Power of the Exponent** (2022)
   - URL: https://arxiv.org/abs/2208.09225
   - 저자: A Kuzmin et al.
   - 인용: 111회
   - 핵심: 광범위한 네트워크의 사후학습 양자화에서 FP8 포맷이 INT8보다 우수

3. **Dual Precision Quantization for Efficient and Accurate Inference** (2025)
   - URL: https://arxiv.org/html/2505.14638v1
   - 날짜: 2025-05-20
   - 핵심: FP8이 모델 정확도 측면에서 INT8보다 유리, INT8은 균일 분포 표현

4. **Gradient distribution-aware INT8 training** (2023)
   - URL: https://www.sciencedirect.com/science/article/abs/pii/S0925231223003922
   - 저자: S Wang et al.
   - 인용: 12회
   - 핵심: INT8 양자화 학습을 위한 Data-aware Dynamic Segmentation Quantization 기법

5. **ZeroQAT: Efficient Quantization-aware Training** (2025)
   - URL: https://arxiv.org/abs/2509.00031
   - 저자: Q Tan et al.
   - 핵심: 양자화 오류 완화 및 처리를 위한 양자화 가중치, 클리핑 임계값, 등가 변환 공동 학습

6. **Low-bit Model Quantization for Deep Neural Networks** (2025)
   - URL: https://arxiv.org/abs/2505.05530
   - 저자: K Liu et al.
   - 인용: 3회
   - 핵심: DNN의 저비트 양자화에 대한 최근 5년간 진행 상황 조사

7. **Low-bit Quantization of Neural Networks for Efficient Inference** (2019)
   - URL: https://arxiv.org/abs/1902.06822
   - 저자: Y Choukroun et al.
   - 인용: 524회
   - 핵심: 가중치와 활성화 모두에 대한 MMSE(Minimum Mean Squared Error) 문제로 선형 양자화 공식화

8. **Quantizing deep convolutional networks for efficient inference** (2018)
   - URL: https://arxiv.org/abs/1806.08342
   - 저자: R Krishnamoorthi
   - 인용: 1482회
   - 핵심: 양자화 인식 학습의 이점 이해를 위한 4비트 양자화 실험

---

## 5. 추가 관련 자료

### GitHub 저장소

1. **Awesome-Riemannian-Deep-Learning**
   - URL: https://github.com/GitZH-Chen/Awesome-Riemannian-Deep-Learning
   - 날짜: 2025-04-13 업데이트
   - 내용: 리만 딥러닝 관련 논문, 책, 튜토리얼, 리소스 모음

2. **intel/neural-compressor**
   - URL: https://github.com/intel/neural-compressor
   - 내용: SOTA 저비트 LLM 양자화 (INT8/FP8/INT4/FP4/NF4) 및 희소성 지원

### 도구 및 라이브러리

1. **geoopt** (v0.5.0+)
   - 용도: 쌍곡/구면 투영을 위한 리만 기하학 라이브러리
   - 추천 사항: requirements.txt에 포함됨

2. **bitsandbytes** (v0.41.0+)
   - 용도: 양자화 및 최적화
   - 추천 사항: requirements.txt에 포함됨

---

## 핵심 트렌드 분석

### 1. 모듈성과 조합성의 중요성 증가
- 2024-2025년 연구들이 모듈식 아키텍처의 조합적 일반화 능력 강조
- 태스크 독립적 모듈의 재사용을 통한 효율성 및 전이 학습 성능 향상
- 인지 과학에서 영감을 받은 계층적 모듈 구조 (VCogM 등)

### 2. 다중 기하학 공간 활용
- 쌍곡 공간: 계층적 데이터 표현에 탁월 (인용 435회 논문)
- 구면 공간: 주기적/순환 데이터 처리
- 유클리드 공간: 일반 연속 데이터
- 2025년 RiemannGFM 등 product bundle로 다중 기하학 통합 추세

### 3. 스케일 강건성의 필요성
- 스케일 등변성 연구 활발 (2023-2025)
- Fourier 레이어, 분해 합성곱 등 다양한 접근법
- FiLM 기반 조건부 정규화가 실용적 해법으로 자리잡음

### 4. 효율적 양자화 기술 발전
- FP8이 INT8 대비 정확도와 효율성에서 우위 (2024년 연구)
- QAT(Quantization-Aware Training)가 PTQ보다 정확도 우수
- 레벨별 차등 비트폭 전략 (L0: INT8, L1: FP8, L2-L3: FP16 학습/INT8 추론)

---

## 가이드와의 연관성

본 가이드의 핵심 컴포넌트들이 최신 연구 트렌드와 높은 일치도를 보임:

1. **MGP (Multi-Geometry Projection)**: 쌍곡/구면/유클리드 공간 병렬 활용은 2020-2025년 리만 기하학 딥러닝 연구의 핵심 방향

2. **CSE (Continuous Scale-Equivariant)**: 2023-2025년 스케일 등변성 연구와 FiLM 기반 조건부 정규화 연구가 이론적 기반 제공

3. **32개 계층적 시드**: 모듈식 조합 학습 연구(239회 인용)와 인지 영감 아키텍처(VCogM) 연구가 설계 철학 뒷받침

4. **양자화 전략**: FP8/INT8 차등 비트폭 전략이 2024년 최신 연구 결과와 일치

---

## 추천 후속 조사 항목

1. **신경과학 기반 모듈 설계**: 뇌의 기능적 특화 영역 연구
2. **메타학습 및 few-shot 학습**: T06 Meta-Learner 구현을 위한 최신 기법
3. **설명가능성 및 해석성**: 시드 라우터 게이트 가중치 해석 방법론
4. **벤치마크 데이터셋**: 각 레벨별 표준 평가 데이터셋 조사
5. **하드웨어 가속**: NPU/TPU에서의 효율적 다중 기하학 연산 구현


